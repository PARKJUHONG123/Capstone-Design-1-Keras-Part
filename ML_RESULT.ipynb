{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Model and Get Computer's Opinion from Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from konlpy.tag import Twitter\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model_pname = load_model('ML_PNAME.h5')\n",
    "model_pmake = load_model('ML_PMAKE.h5')\n",
    "\n",
    "with open('mpbase_pname_tokenizer.json') as f:\n",
    "    mpbase_pname_data = json.load(f)\n",
    "    mpbase_pname_tokenizer = tokenizer_from_json(mpbase_pname_data)\n",
    "\n",
    "with open('mpbase_pmake_tokenizer.json') as f:\n",
    "    mpbase_pmake_data = json.load(f)\n",
    "    mpbase_pmake_tokenizer = tokenizer_from_json(mpbase_pmake_data)\n",
    "\n",
    "with open('pname_tokenizer.json') as f:\n",
    "    pname_data = json.load(f)\n",
    "    pname_tokenizer = tokenizer_from_json(pname_data)\n",
    "\n",
    "with open('pmake_tokenizer.json') as f:\n",
    "    pmake_data = json.load(f)\n",
    "    pmake_tokenizer = tokenizer_from_json(pmake_data)\n",
    "\n",
    "def split(text):\n",
    "    results = []\n",
    "    twitter = Twitter()\n",
    "    malist = twitter.pos(text, norm=True, stem=True)\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\", \"Foreign\", \"Number\", \"Alpha\"]:\n",
    "             results += word[0] + \" \"\n",
    "    return results\n",
    "\n",
    "def vectorize_sequences_pname(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "def vectorize_sequences_pmake(sequences, dimension = 14000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "fr = open(\"input.txt\", \"r\", encoding=\"UTF8\")\n",
    "fw = open(\"output.txt\", \"w\", encoding=\"UTF8\")\n",
    "\n",
    "while True:\n",
    "    x = fr.readline()\n",
    "    if not x : break\n",
    "    \n",
    "    x_list = [\"\" for row in range(1)]\n",
    "    x_list[0] = ''.join(split(x))\n",
    "    pname_sequences = mpbase_pname_tokenizer.texts_to_sequences(x_list)\n",
    "    pmake_sequences = mpbase_pmake_tokenizer.texts_to_sequences(x_list)\n",
    "\n",
    "    pname_vector = vectorize_sequences_pname(pname_sequences)\n",
    "    pmake_vector = vectorize_sequences_pmake(pmake_sequences)\n",
    "    \n",
    "    predictions_pname = model_pname.predict(pname_vector)\n",
    "    predictions_pmake = model_pmake.predict(pmake_vector)\n",
    "    \n",
    "    reverse_word_map_pname = dict(map(reversed, pname_tokenizer.word_index.items()))\n",
    "    reverse_word_map_pmake = dict(map(reversed, pmake_tokenizer.word_index.items()))\n",
    "    \n",
    "    input_pname = predictions_pname[0]\n",
    "    input_pmake = predictions_pmake[0]\n",
    "    \n",
    "    idx_pname = np.flip(np.argsort(input_pname), 0)\n",
    "    idx_pmake = np.flip(np.argsort(input_pmake), 0)\n",
    "\n",
    "    for j in idx_pname[:1]:\n",
    "        pname_result = reverse_word_map_pname[j]\n",
    "        pname_percent = \"{:4.2f}\".format(100 * input_pname[j])\n",
    "        fw.write(pname_result + \"\\n\")\n",
    "        fw.write(pname_percent + \"\\n\")\n",
    "        \n",
    "    for j in idx_pmake[:1]:\n",
    "        pmake_result = reverse_word_map_pmake[j]\n",
    "        pmake_percent = \"{:4.2f}\".format(100 * input_pmake[j])\n",
    "        fw.write(pmake_result + \"\\n\")\n",
    "        fw.write(pmake_percent + \"\\n\")\n",
    "        \n",
    "fr.close()\n",
    "fw.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
